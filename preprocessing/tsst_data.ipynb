{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing of TSST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from IPython.display import Video, Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Colletion of Videos and creating Audios\n",
    "First I collect all TSST video files (including the ones from the second camera, but they are currently not used) and convert them to mp3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all TSST video files\n",
    "video_files_tsst = glob.glob(\"/data/dst_tsst_22_bi_multi_nt_lab/raw/mainstudy/**/*.MOV\",recursive=True)\n",
    "video_files_tsst2 = glob.glob(\"/data/dst_tsst_22_bi_multi_nt_lab/raw/mainstudy/**/*.MP4\",recursive=True)\n",
    "\n",
    "# filter out all _2 videos (video camera splits after 12:30min into two files, speech task always in first video)\n",
    "video_files_tsst = [path for path in video_files_tsst if not re.search(\"_2.MOV$\", path, re.IGNORECASE)]\n",
    "video_files_tsst2 = [path for path in video_files_tsst2 if not re.search(\"_2.MOV$\", path, re.IGNORECASE)]\n",
    "\n",
    "# wrong filename (corrected on vmc, but not synched yet so here done by hand -> can be deleted afterwards)\n",
    "video_files_tsst = [path for path in video_files_tsst if not re.search(\"_1b.MOV$\", path, re.IGNORECASE)]\n",
    "\n",
    "print(\"I found\", len(video_files_tsst), \"TSST videos\")\n",
    "print(\"I found\", len(video_files_tsst2), \"secondary TSST videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all .MOV files into wav files - takes a while\n",
    "audio_files_tsst = []\n",
    "for input_file in video_files_tsst:\n",
    "    output_file = \"/data/dst_tsst_22_bi_multi_nt_lab/processed/audio_files/\" + input_file.rsplit('/', 1)[1][:-3] + \"wav\"\n",
    "    print(input_file, output_file)\n",
    "    # skip creating .wav file if it already exists\n",
    "    if not os.path.exists(output_file):\n",
    "        clip = VideoFileClip(input_file)\n",
    "        clip.audio.write_audiofile(output_file) #, codec='pcm_s16le'\n",
    "    audio_files_tsst.append(output_file)\n",
    "    AudioFileClip(output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Segmentation of Audio File to only include speech task\n",
    "Next the start of the speech task is manually checked and saved in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start-times for segmentation in seconds after first camera start (manual inspection)\n",
    "segment_starts = {'CZ513556_tsst_video': 35, 'CS181122_tsst_video': 30, 'PD513556_tsst_video_': 30, 'JK261022_tsst_video': 49, 'AZ573556_tsst_video': 0, 'JB011222_tsst_video': 23, 'DQ563556_tsst_video': 28, 'DK011122_tsst_video': 28, 'SB041122_tsst_video': 27, 'DC553556_tsst_video': 28, 'AS050123_tsst_video': 30, 'ML031122_tsst_video': 32, 'MK230123_tsst_video_1': 32, 'MX463556_tsst_video': 30, 'MG130123_tsst_video': 24, 'KO433656_tsst_video': 29, 'SB021122_tsst_video': 32, 'SE141122_tsst_video': 30, 'EC250123_tsst_video_1': 28, 'KK483556_tsst_video_1a': 33, 'SS291122_tsst_movie': 33, 'MS021222_tsst_video': 28, 'KT463556_tsst_video': -1, 'JB190123_tsst_video': 30, 'OQ503556_tsst_video': 28, 'NE563556_tsst_video': 28, \"TB493656_tsst_video\":29, \"NI433856_tsst_video\":30, \"JM463656_tsst_video\":28, \"BS323856_tsst_video\":27, \"SB443756_tsst_video\":30, \"KH553656_tsst_video\":28, \"FC483856_tsst_video\":28, \"TF483656_tsst_video\":28, \"JH373756_tsst_video\":26, \"OM423756_tsst_video\":29, \"KK483556_tsst_video_1\": 33}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for new audios, which are not transcribed with start time in the dictionary above\n",
    "to_check = []\n",
    "print(sorted(segment_starts.keys()))\n",
    "for video_path in video_files_tsst:\n",
    "    #token = video_path[48:56]\n",
    "    token =  video_path.rsplit('/', 1)[1][:-4]\n",
    "    if token not in segment_starts.keys():\n",
    "        audio_path = \"/data/dst_tsst_22_bi_multi_nt_lab/processed/audio_files/\" + token + \".wav\"\n",
    "        to_check.append(audio_path)\n",
    "print(\"to_check\",to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Snippet to listen and manually transcribe start time for new audios\n",
    "sample_audio = to_check[0]\n",
    "print(sample_audio)\n",
    "\n",
    "Audio(sample_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_audio(audio_file, start):\n",
    "    \"\"\"\n",
    "    This function segments an audio file from a given start time to 5 minutes later, to capture only the speech task as an audio file.\n",
    "    @param audio_file: path to audio file\n",
    "    @param start: start of speech task in seconds\n",
    "    @return: path to segmented audio file\n",
    "    \"\"\"\n",
    "    audio = AudioFileClip(audio_file)\n",
    "    segment_length = 300 # 5minutes\n",
    "    end = start + segment_length\n",
    "    new_path = \"/data/dst_tsst_22_bi_multi_nt_lab/processed/audio_files/\" + audio_file.rsplit('/', 1)[1][:-4] + \"_segment.wav\"\n",
    "    if start == -1:\n",
    "        return None\n",
    "    if not os.path.exists(new_path):\n",
    "        segment = audio.subclip(start, end)\n",
    "        segment.write_audiofile(new_path)\n",
    "    return new_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Creating and Filtering DataFrame\n",
    "\n",
    "I first create a dataframe with token, video_path(s), audio_path, segmented audio path and segment start in seconds. I then merge it with VAS self-assessed stress information from the participant.csv and calculate the delat before and after the stress test, as well filter out anyone that does not speak German as a first language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = {}\n",
    "for vfile in (video_files_tsst + video_files_tsst2):\n",
    "    token = vfile.split(\"/\")[-1][:8]\n",
    "    if \"cam\" in vfile:\n",
    "        name = \"TSST2\"\n",
    "    else:\n",
    "        name = \"TSST\"\n",
    "    if token not in video_data:\n",
    "        video_data[token] = {\"TSST\": None, \"TSST2\": None}\n",
    "    video_data[token][name] = vfile\n",
    "\n",
    "audio_data = {}\n",
    "for audio_name, start_num in segment_starts.items():\n",
    "    audio_file = \"/data/dst_tsst_22_bi_multi_nt_lab/processed/audio_files/\" + audio_name + \".wav\"\n",
    "    token = audio_name[:8]\n",
    "    audio_segment = segment_audio(audio_file, start_num)\n",
    "    if token not in audio_data:\n",
    "        audio_data[token] = {\"audio_file\": None, \"audio_segment\": None, \"segment_start\": None}\n",
    "    audio_data[token][\"audio_file\"] = audio_file\n",
    "    audio_data[token][\"audio_segment\"] = audio_segment\n",
    "    audio_data[token][\"segment_start\"] = start_num\n",
    "\n",
    "data = []\n",
    "for token, values in video_data.items():\n",
    "    audio_file = audio_data[token][\"audio_file\"] if token in audio_data else None\n",
    "    audio_segment = audio_data[token][\"audio_segment\"] if token in audio_data else None\n",
    "    segment_start = audio_data[token][\"segment_start\"] if token in audio_data else None\n",
    "    data.append([token, values[\"TSST\"], values[\"TSST2\"], audio_file, audio_segment, segment_start])\n",
    "\n",
    "tsst_data = pd.DataFrame(data, columns=[\"token\", \"TSST_video\", \"TSST2_video\", \"TSST_audio\", \"TSST_audio_segment\", \"segment_start\"])\n",
    "display(tsst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_duration(video_path):\n",
    "    \"\"\"\n",
    "    Function to get the duration of a video\n",
    "    @param video_path: path to video\n",
    "    @return: duration of clip in seconds\n",
    "    \"\"\"\n",
    "    clip = VideoFileClip(video_path)\n",
    "    return clip.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all participant information\n",
    "participants = pd.read_csv(\"/data/dst_tsst_22_bi_multi_nt_lab/processed/participant.csv\")\n",
    "display(participants[[\"token\", \"tsst_vas_stress_T1\", \"tsst_vas_stress_T2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete non-native German speakers from dataframe\n",
    "tokens_to_drop = participants.loc[participants['mothertongue'] != 'Deutsch', 'token'].tolist()\n",
    "tsst_data = tsst_data[~tsst_data['token'].isin(tokens_to_drop)]\n",
    "\n",
    "# delete all length less than 10minutes (original video) (and delete all NaN videos)\n",
    "tsst_data = tsst_data[tsst_data['TSST_video'].apply(lambda x: get_video_duration(x) >= 600 if pd.notnull(x) else False)]\n",
    "\n",
    "# add vas_stress data and calculate delta\n",
    "tsst_data = pd.merge(tsst_data, participants[['token','tsst_vas_stress_T1','tsst_vas_stress_T2']], on=\"token\", how=\"inner\")\n",
    "tsst_data['stress_delta'] = tsst_data['tsst_vas_stress_T2'] - tsst_data['tsst_vas_stress_T1']\n",
    "\n",
    "display(tsst_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Saving DataFrame as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsst_data.to_csv(\"/data/dst_tsst_22_bi_multi_nt_lab/processed/audio_files/tsst_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
