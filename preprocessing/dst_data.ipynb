{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from IPython.display import Video, Audio\n",
    "import subprocess\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing of DST Data\n",
    "\n",
    "#### Collecting Data and creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all DST video files\n",
    "video_files_dst = glob.glob(\"/data/dst_tsst_22_bi_multi_nt_lab/raw/mainstudy/**/*.webm\",recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DST files by token into dictionary\n",
    "videos_dst = {}\n",
    "for file in video_files_dst:\n",
    "    pattern = r'([A-Z]{2}\\d+)'\n",
    "    token = re.search(pattern, file)[0]\n",
    "    if token not in videos_dst.keys():\n",
    "        videos_dst[token] = [file]\n",
    "    else:\n",
    "        videos_dst[token].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate all tokens with more than three files in the value-list (started multiple tests)\n",
    "videos_dst = {key: value for key, value in videos_dst.items() if len(value) <= 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with token and paths as columns\n",
    "data = []\n",
    "\n",
    "for token, file_paths in videos_dst.items():\n",
    "    speech_task = None\n",
    "    math_task = None\n",
    "    introduction = None\n",
    "\n",
    "    for path in file_paths:\n",
    "        if \"speechTask\" in path:\n",
    "            speech_task = path\n",
    "        elif \"mathTask\" in path:\n",
    "            math_task = path\n",
    "        elif \"introduction\" in path:\n",
    "            introduction = path\n",
    "    data.append([token, speech_task, math_task, introduction])\n",
    "\n",
    "dst_data = pd.DataFrame(data, columns=['token', 'speechTask', 'mathTask', 'introduction'])\n",
    "\n",
    "display(dst_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Convert .webm to .wav and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert webm to wav\n",
    "def convert_to_wav(video_path, audio_path):\n",
    "    #clip = VideoFileClip(video_path)\n",
    "    #clip.audio.write_audiofile(audio_path)\n",
    "    audio = AudioSegment.from_file(video_path, format='webm')\n",
    "    audio.export(audio_path, format='wav')\n",
    "\n",
    "\n",
    "for index, row in dst_data.iterrows():\n",
    "    # Convert speechTask\n",
    "    speech_task_video_path = row['speechTask']\n",
    "    speech_task_audio_path = \"/data/dst_tsst_22_bi_multi_nt_lab/processed/audio_files/\" + row[\"token\"] + \"_dst_speechTask.wav\"\n",
    "    if not os.path.exists(speech_task_audio_path):\n",
    "        convert_to_wav(speech_task_video_path, speech_task_audio_path)\n",
    "    dst_data.loc[index, 'speechTask_audio'] = speech_task_audio_path\n",
    "\n",
    "    # Convert mathTask\n",
    "    math_task_video_path = row['mathTask']\n",
    "    math_task_audio_path = \"/data/dst_tsst_22_bi_multi_nt_lab/processed/audio_files/\" + row[\"token\"] + \"_dst_mathTask.wav\"\n",
    "    if not os.path.exists(math_task_audio_path):\n",
    "        convert_to_wav(math_task_video_path, math_task_audio_path)\n",
    "    dst_data.loc[index, 'mathTask_audio'] = math_task_audio_path\n",
    "\n",
    "display(dst_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dst_data.loc[0,\"mathTask_audio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(dst_data.loc[0,\"speechTask_audio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cut out silences in speechTask\n",
    "# TODO: dataframe, conversion simplify? -> only need speechTask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
