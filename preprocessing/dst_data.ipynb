{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from IPython.display import Video, Audio\n",
    "import subprocess\n",
    "from pydub import AudioSegment\n",
    "import parselmouth\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing of DST Data\n",
    "\n",
    "#### Collecting Data and creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all DST video files\n",
    "video_files_dst = glob.glob(\"/data/dst_tsst_22_bi_multi_nt_lab/raw/mainstudy/**/*.webm\",recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DST files by token into dictionary\n",
    "videos_dst = {}\n",
    "for file in video_files_dst:\n",
    "    pattern = r'([A-Z]{2}\\d+)'\n",
    "    token = re.search(pattern, file)[0]\n",
    "    if token not in videos_dst.keys():\n",
    "        videos_dst[token] = [file]\n",
    "    else:\n",
    "        videos_dst[token].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate all tokens with more than three files in the value-list (started multiple tests)\n",
    "videos_dst = {key: value for key, value in videos_dst.items() if len(value) <= 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with token and paths as columns\n",
    "data = []\n",
    "\n",
    "for token, file_paths in videos_dst.items():\n",
    "    speech_task = None\n",
    "    # only speech task is needed\n",
    "    #math_task = None\n",
    "    #introduction = None\n",
    "\n",
    "    for path in file_paths:\n",
    "        if \"speechTask\" in path:\n",
    "            speech_task = path\n",
    "    data.append([token, speech_task])\n",
    "\n",
    "dst_data = pd.DataFrame(data, columns=['token', 'speechTask_webm'])\n",
    "\n",
    "display(dst_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Convert .webm to .wav and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert webm to wav\n",
    "def convert_to_wav(video_path, audio_path):\n",
    "    #clip = VideoFileClip(video_path)\n",
    "    #clip.audio.write_audiofile(audio_path)\n",
    "    audio = AudioSegment.from_file(video_path, format='webm')\n",
    "    audio.export(audio_path, format='wav')\n",
    "\n",
    "\n",
    "for index, row in dst_data.iterrows():\n",
    "    # Convert speechTask\n",
    "    speech_task_video_path = row['speechTask_webm']\n",
    "    speech_task_audio_path = \"/data/dst_tsst_22_bi_multi_nt_lab/processed/audio_files/\" + row[\"token\"] + \"_dst_speechTask.wav\"\n",
    "    if not os.path.exists(speech_task_audio_path):\n",
    "        convert_to_wav(speech_task_video_path, speech_task_audio_path)\n",
    "    dst_data.loc[index, 'speechTask_audio'] = speech_task_audio_path\n",
    "\n",
    "display(dst_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Cutting out silences\n",
    "The DST speech task includes three questions, to which the participants have 10 seconds to think of an answer and 20 seconds to answer. The \"thinking\"-silences should be cut out.\n",
    "\n",
    "Option A: cut always 10-30, 40-60 and 70-90\n",
    "Option B: cut depending on amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_token in ['NI433856', 'JK261022', 'TH313556', 'MG130123']:\n",
    "    sample_audio = dst_data.loc[dst_data['token'] == sample_token, 'speechTask_audio'].values[0]\n",
    "    # wav_path already created for sample files above\n",
    "    snd = parselmouth.Sound(sample_audio)\n",
    "    plt.figure()\n",
    "    plt.title(sample_token)\n",
    "    plt.plot(snd.xs(), snd.values.T)\n",
    "    plt.xlim([snd.xmin, snd.xmax])\n",
    "    plt.ylabel(\"amplitude\")\n",
    "    plt.xlabel(\"time [s]\")\n",
    "    plt.axvspan(10, 30, color='red', alpha=0.3)\n",
    "    plt.axvspan(40, 60, color='red', alpha=0.3)\n",
    "    plt.axvspan(70, 90, color='red', alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dst_data[\"speechTask_audio\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option A: cutting ridgidly\n",
    "# Set the desired start and end times for each part (in seconds)\n",
    "part1_start = 10\n",
    "part1_end = 30\n",
    "part2_start = 40\n",
    "part2_end = 60\n",
    "part3_start = 70\n",
    "\n",
    "for index, row in dst_data.iterrows():\n",
    "    # Load the original audio file\n",
    "    file = row[\"speechTask_audio\"]\n",
    "    audio_full = AudioFileClip(file)\n",
    "\n",
    "    # set part3_end to duration of file, as sometimes it is a few milliseconds shorter than 90 seconds\n",
    "    part3_end = audio_full.duration\n",
    "\n",
    "    # Extract the three parts from the original audio\n",
    "    part1 = audio_full.subclip(part1_start, part1_end)\n",
    "    part2 = audio_full.subclip(part2_start, part2_end)\n",
    "    part3 = audio_full.subclip(part3_start, part3_end)\n",
    "\n",
    "    # Create path/filename for new segments\n",
    "    path1 = file[:-4] + \"_part1.wav\"\n",
    "    path2 = file[:-4] + \"_part2.wav\"\n",
    "    path3 = file[:-4] + \"_part3.wav\"\n",
    "\n",
    "    # check if path already exists, if not write segment\n",
    "    for part, path in zip([part1, part2, part3], [path1, path2, path3]):\n",
    "        if not os.path.exists(path):\n",
    "            part.write_audiofile(path, fps=16000) # downsample to 16kHz\n",
    "\n",
    "    # add paths to segments to dataframe\n",
    "    dst_data.loc[index, 'part1'] = path1\n",
    "    dst_data.loc[index, 'part2'] = path2\n",
    "    dst_data.loc[index, 'part3'] = path3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dst_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Saving Dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_data.to_csv(\"/data/dst_tsst_22_bi_multi_nt_lab/processed/audio_files/dst_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Snippet to check specific files\n",
    "file = dst_data[\"part1\"][5]\n",
    "print(file)\n",
    "Audio(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
